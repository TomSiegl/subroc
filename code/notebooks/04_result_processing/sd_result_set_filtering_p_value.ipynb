{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering a Result Set Based on the Statistical Significance of Each Subgroup\n",
    "## Statistical Significance is Determined by Random Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Values for Papermill Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "PARAM_RESULT_SET_PATH = \"../outputs/p_value_augmented_result_set.csv\"\n",
    "PARAM_FILTERING_RESULT_FILENAME = \"p_value_filtered_result_set.csv\"\n",
    "\n",
    "PARAM_SIGNIFICANCE_ALPHA = 0.05\n",
    "PARAM_MULTIPLE_TESTING_CORRECTION = \"bonferroni\"\n",
    "PARAM_FILTER_NAN_P_VALUES = \"True\"\n",
    "PARAM_FILTER_NEGATIVE_FILTERING_INTERESTINGNESS = \"True\"\n",
    "PARAM_REMOVE_FILTERING_ATTRIBUTES = \"False\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subroc import util\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# fill environment variables into params\n",
    "PARAM_RESULT_SET_PATH = util.prepend_experiment_output_path(PARAM_RESULT_SET_PATH)\n",
    "\n",
    "# get environment variables\n",
    "STAGE_OUTPUT_PATH = os.environ.get(\"STAGE_OUTPUT_PATH\", \"../outputs\")\n",
    "\n",
    "PARAM_FILTER_NAN_P_VALUES = util.str_to_bool(PARAM_FILTER_NAN_P_VALUES)\n",
    "PARAM_FILTER_NEGATIVE_FILTERING_INTERESTINGNESS = util.str_to_bool(PARAM_FILTER_NEGATIVE_FILTERING_INTERESTINGNESS)\n",
    "PARAM_REMOVE_FILTERING_ATTRIBUTES = util.str_to_bool(PARAM_REMOVE_FILTERING_ATTRIBUTES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Result Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_set = pd.read_csv(f\"{PARAM_RESULT_SET_PATH}\")\n",
    "result_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the Result Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_columns = result_set.columns.values.tolist()\n",
    "\n",
    "filtering_attributes = [\"p-value\", \"filtering interestingness\"]\n",
    "if not PARAM_REMOVE_FILTERING_ATTRIBUTES:\n",
    "    filtered_result_set = pd.DataFrame(columns=original_columns + [\"corrected p-value\"])\n",
    "else:\n",
    "    filtered_result_set = pd.DataFrame(columns=[original_column for original_column in original_columns if original_column not in filtering_attributes])\n",
    "\n",
    "all_patterns = result_set[\"pattern\"].tolist()\n",
    "all_pvalues = np.array(result_set[\"p-value\"].tolist())\n",
    "\n",
    "# Multiple Testing Correction Method\n",
    "if len(result_set) > 0:\n",
    "    if PARAM_FILTER_NAN_P_VALUES:\n",
    "        no_nan_mask = np.logical_not(np.isnan(all_pvalues))\n",
    "        no_nan_pvalues = all_pvalues[no_nan_mask]\n",
    "        no_nan_reject, no_nan_pvals_corrected, _, _ = multipletests(no_nan_pvalues, PARAM_SIGNIFICANCE_ALPHA, PARAM_MULTIPLE_TESTING_CORRECTION)\n",
    "\n",
    "        pvals_corrected = np.array([np.nan for _ in range(len(all_pvalues))])\n",
    "        pvals_corrected[no_nan_mask] = no_nan_pvals_corrected\n",
    "        reject = np.array([False for _ in range(len(all_pvalues))])\n",
    "        reject[no_nan_mask] = no_nan_reject\n",
    "    else:\n",
    "        reject, pvals_corrected, _, _ = multipletests(all_pvalues, PARAM_SIGNIFICANCE_ALPHA, PARAM_MULTIPLE_TESTING_CORRECTION)\n",
    "\n",
    "for i in range(len(result_set)):\n",
    "    row = result_set.iloc[i]\n",
    "    pattern = row[\"pattern\"]\n",
    "    filtering_interestingness = row[\"filtering interestingness\"]\n",
    "    pvalue = row[\"p-value\"]\n",
    "    pvalue_corrected = pvals_corrected[i]\n",
    "    curr_reject = reject[i]\n",
    "\n",
    "    print(f\"pattern: {pattern}\")\n",
    "    print(f\"filtering interestingness: {filtering_interestingness}\")\n",
    "    print(f\"p-value: {pvalue}\")\n",
    "    print(f\"corrected p-value: {pvalue_corrected}\")\n",
    "    print(f\"rejected H_0: {'Yes' if curr_reject else 'No'}\")\n",
    "\n",
    "    # compare the p-value against the critical value\n",
    "    if (PARAM_FILTER_NEGATIVE_FILTERING_INTERESTINGNESS and filtering_interestingness <= 0) or \\\n",
    "            (PARAM_FILTER_NAN_P_VALUES and np.isnan(pvalue)) or \\\n",
    "            not curr_reject:\n",
    "        continue\n",
    "    \n",
    "    # append the augmented instance to metrics_augmented_result_set\n",
    "    if not PARAM_REMOVE_FILTERING_ATTRIBUTES:\n",
    "        filtered_result_set.loc[i] = [row[column] for column in original_columns] + [pvalue_corrected]\n",
    "    else:\n",
    "        filtered_result_set.loc[i] = [row[column] for column in original_columns if column not in filtering_attributes]\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the Filtered Result Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_result_set.to_csv(f\"{STAGE_OUTPUT_PATH}/{PARAM_FILTERING_RESULT_FILENAME}\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subroc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
