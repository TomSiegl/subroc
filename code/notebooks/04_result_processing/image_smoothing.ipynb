{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b304f0ed79c23aa",
   "metadata": {},
   "source": [
    "# Smooth results of notebook 203"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2d367e",
   "metadata": {},
   "source": [
    "## Default Values for Papermill Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e6d334",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "PARAM_IMAGES_IN_DIR = \"../outputs\"\n",
    "PARAM_IMAGE_FILENAMES = [\n",
    "    \"result_factors_analytical_size_average_ranking_loss_maximal_s0_cb0\",\n",
    "    \"result_factors_analytical_size_average_ranking_loss_maximal_s1_cb0\",\n",
    "    \"result_factors_analytical_size_average_ranking_loss_maximal_s0_cb1\",\n",
    "    \"result_factors_analytical_size_roc_auc_score_maximal_s0_cb0\",\n",
    "    \"result_factors_analytical_size_roc_auc_score_maximal_s1_cb0\",\n",
    "    \"result_factors_analytical_size_roc_auc_score_maximal_s0_cb1\",\n",
    "    \"result_factors_analytical_size_prc_auc_score_maximal_s0_cb0\",\n",
    "    \"result_factors_analytical_size_prc_auc_score_maximal_s1_cb0\",\n",
    "    \"result_factors_analytical_size_prc_auc_score_maximal_s0_cb1\",\n",
    "    \"result_factors_analytical_class_balance_average_ranking_loss_maximal_s0_cb0\",\n",
    "    \"result_factors_analytical_class_balance_average_ranking_loss_maximal_s1_cb0\",\n",
    "    \"result_factors_analytical_class_balance_average_ranking_loss_maximal_s0_cb1\",\n",
    "    \"result_factors_analytical_class_balance_roc_auc_score_maximal_s0_cb0\",\n",
    "    \"result_factors_analytical_class_balance_roc_auc_score_maximal_s1_cb0\",\n",
    "    \"result_factors_analytical_class_balance_roc_auc_score_maximal_s0_cb1\",\n",
    "    \"result_factors_analytical_class_balance_prc_auc_score_maximal_s0_cb0\",\n",
    "    \"result_factors_analytical_class_balance_prc_auc_score_maximal_s1_cb0\",\n",
    "    \"result_factors_analytical_class_balance_prc_auc_score_maximal_s0_cb1\",\n",
    "]\n",
    "\n",
    "PARAM_BORDER_SIZE = 10\n",
    "PARAM_KERNEL_WIDTH = 11\n",
    "PARAM_KERNEL_HEIGHT = 11\n",
    "PARAM_KERNEL_STD = 0  # 0 means that the kernel standard deviation is calculated from the kernel size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fc6af40ea0f0a7",
   "metadata": {},
   "source": [
    "## Prepare constant variables that will be used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T06:48:13.595615Z",
     "start_time": "2024-05-18T06:48:12.143470Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from subroc import util\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "PARAM_IMAGES_IN_DIR = util.prepend_experiment_output_path(PARAM_IMAGES_IN_DIR)\n",
    "STAGE_OUTPUT_PATH = os.environ.get(\"STAGE_OUTPUT_PATH\", \"../outputs\")\n",
    "\n",
    "\n",
    "def scale_values(img, min_val, max_val):\n",
    "    img_min_val = -np.inf\n",
    "    img_max_val = np.inf\n",
    "    \n",
    "    for row in img:\n",
    "        for px in row:\n",
    "            img_min_val = max(img_min_val, px)\n",
    "            img_max_val = min(img_max_val, px)\n",
    "    \n",
    "    for row_idx in range(len(img)):\n",
    "        for col_idx in range(len(img[row_idx])):\n",
    "            img[row_idx][col_idx] = (img[row_idx][col_idx] - img_min_val) * ((max_val-min_val)/(img_max_val-img_min_val)) + min_val\n",
    "    \n",
    "    return img_min_val, img_max_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd799f7b28f7b6db",
   "metadata": {},
   "source": [
    "# Compute smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81313261d8671e8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T07:10:18.815721Z",
     "start_time": "2024-05-18T07:10:11.345829Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "smooth_imgs = []\n",
    "for data_filename in tqdm(PARAM_IMAGE_FILENAMES):\n",
    "    df = pd.read_csv(f\"{PARAM_IMAGES_IN_DIR}/{data_filename}.csv\")\n",
    "    \n",
    "    param_col = \"negative_class_ratio\"\n",
    "    if \"size\" in data_filename:\n",
    "        param_col = \"size\"\n",
    "\n",
    "    num_correlations = df[\"correlation\"].nunique()\n",
    "    num_param = df[param_col].nunique()\n",
    "\n",
    "    img = np.array([[df.iloc[i*num_correlations + j][\"score\"] for j in range(num_correlations)] for i in range(num_param)])\n",
    "    # input_min_val, input_max_val = scale_values(img, 0, 255)\n",
    "    \n",
    "    img_with_border = cv2.copyMakeBorder(img, PARAM_BORDER_SIZE, PARAM_BORDER_SIZE, PARAM_BORDER_SIZE, PARAM_BORDER_SIZE, cv2.BORDER_REPLICATE)\n",
    "    smooth_img_with_border = cv2.GaussianBlur(img_with_border, (PARAM_KERNEL_WIDTH,PARAM_KERNEL_HEIGHT), PARAM_KERNEL_STD)\n",
    "    smooth_img = smooth_img_with_border[PARAM_BORDER_SIZE:-PARAM_BORDER_SIZE, PARAM_BORDER_SIZE:-PARAM_BORDER_SIZE]\n",
    "    \n",
    "    # scale_values(smooth_img, input_min_val, input_max_val)\n",
    "    smooth_imgs.append(smooth_img)\n",
    "    \n",
    "    smooth_img_list_of_pixel_dicts = []\n",
    "    if param_col == \"size\":\n",
    "        for i in range(num_param):\n",
    "            for j, correlation in enumerate(np.linspace(-1, 1, num=num_correlations)):\n",
    "                smooth_img_list_of_pixel_dicts.append({param_col: i+2, \"correlation\": correlation, \"score\": smooth_img[i][j]})\n",
    "    else:\n",
    "        for i, param in enumerate(np.linspace(0, 1, num=num_param+1, endpoint=False)[1:]):\n",
    "            for j, correlation in enumerate(np.linspace(-1, 1, num=num_correlations)):\n",
    "                smooth_img_list_of_pixel_dicts.append({param_col: param, \"correlation\": correlation, \"score\": smooth_img[i][j]})\n",
    "    smooth_img_df = pd.DataFrame(smooth_img_list_of_pixel_dicts)\n",
    "    \n",
    "    smooth_img_df.to_csv(f\"{STAGE_OUTPUT_PATH}/{data_filename}_smooth.csv\", index=False)\n",
    "\n",
    "    # plt.matshow(smooth_img)\n",
    "    # plt.title(data_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
