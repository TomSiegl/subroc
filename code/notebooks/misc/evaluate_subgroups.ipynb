{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Subgroups on the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Values for Papermill Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "PARAM_DATA_IN_PATH = \"../../data\"\n",
    "PARAM_DATASET_NAME = \"OpenML Adult\"\n",
    "PARAM_DATASET_STAGE = 5  # 4=predicted, 5=permuted\n",
    "\n",
    "PARAM_PATTERNS_IN_PATH = \"../outputs/0.7_0.8_picked_pattern.csv\"\n",
    "\n",
    "PARAM_SEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subroc.datasets.metadata import to_DatasetName\n",
    "from subroc.datasets.reader import DatasetReader, DatasetStage\n",
    "from subroc import util\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "PARAM_DATA_IN_PATH = util.prepend_experiment_output_path(PARAM_DATA_IN_PATH)\n",
    "PARAM_PATTERNS_IN_PATH = util.prepend_experiment_output_path(PARAM_PATTERNS_IN_PATH)\n",
    "\n",
    "STAGE_OUTPUT_PATH = os.environ.get(\"STAGE_OUTPUT_PATH\", \"../outputs\")\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"Computer Modern Roman\",\n",
    "    \"figure.figsize\": [5.1483, 5.1483],\n",
    "})\n",
    "\n",
    "# Dataset\n",
    "dataset_reader = DatasetReader(PARAM_DATA_IN_PATH)\n",
    "\n",
    "DATASET_NAME = to_DatasetName(PARAM_DATASET_NAME)\n",
    "\n",
    "if DATASET_NAME is None:\n",
    "    print(f\"dataset name '{PARAM_DATASET_NAME}' not supported.\")\n",
    "\n",
    "DATASET_STAGE = DatasetStage(PARAM_DATASET_STAGE)\n",
    "\n",
    "# read data and preprocess it for the model\n",
    "(_, test_data), dataset_meta = dataset_reader.read_dataset(DATASET_NAME, DATASET_STAGE)\n",
    "\n",
    "evaluation_patterns = pd.read_csv(PARAM_PATTERNS_IN_PATH)\n",
    "\n",
    "rng = np.random.default_rng(PARAM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subroc.util import print_metric_colored, create_subgroup, from_str_Conjunction\n",
    "from subroc.quality_functions.sklearn_metrics import soft_classification_metrics\n",
    "from subroc.quality_functions.base_qf import label_balance_fraction\n",
    "from subroc.metrics import average_ranking_loss, prc_auc_score\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay, precision_recall_curve\n",
    "from termcolor import cprint\n",
    "\n",
    "for pattern in [\"Dataset\"] + list(evaluation_patterns):\n",
    "    print(f\"################ {pattern} ################\")\n",
    "\n",
    "    subgroup = create_subgroup(test_data, from_str_Conjunction(pattern).selectors)\n",
    "    subgroup_data = test_data[subgroup.representation]\n",
    "\n",
    "    print(f\"cover size: {len(subgroup_data)}\")\n",
    "    print(f\"class balance: {label_balance_fraction(subgroup_data[dataset_meta.gt_name])}\")\n",
    "    print(f\"NCR: {sum(test_data.loc[subgroup.representation][dataset_meta.gt_name] == 0) / len(test_data.loc[subgroup.representation])}\")\n",
    "\n",
    "    for metric in soft_classification_metrics:\n",
    "        try:\n",
    "            test_y_numpy = subgroup_data[dataset_meta.gt_name].to_numpy()\n",
    "            metric_value = metric(test_y_numpy, subgroup_data[dataset_meta.score_name])\n",
    "            print_metric_colored(metric.__name__, metric_value)   \n",
    "        except ValueError:\n",
    "            cprint(f\"{metric.__name__}: ValueError\", color=\"red\")\n",
    "    \n",
    "    dataset_sorted_by_score = subgroup_data.sort_values(dataset_meta.score_name)\n",
    "    scores_sorted = dataset_sorted_by_score.loc[:, dataset_meta.score_name]\n",
    "    gt_sorted_by_score = dataset_sorted_by_score.loc[:, dataset_meta.gt_name]\n",
    "    sorted_to_original_index = [index for index, _ in dataset_sorted_by_score.iterrows()]\n",
    "    sorted_subgroup_representation = \\\n",
    "        [subgroup.representation[original_index] for original_index in sorted_to_original_index]\n",
    "    sorted_subgroup_y_true = gt_sorted_by_score[sorted_subgroup_representation].to_numpy()\n",
    "    sorted_subgroup_y_pred = scores_sorted[sorted_subgroup_representation].to_numpy()\n",
    "    print(f\"average_ranking_loss: {average_ranking_loss(sorted_subgroup_y_true, sorted_subgroup_y_pred)}\")\n",
    "\n",
    "    print(f\"prc_auc_score: {prc_auc_score(subgroup_data[dataset_meta.gt_name], subgroup_data[dataset_meta.score_name])}\")\n",
    "\n",
    "    RocCurveDisplay.from_predictions(subgroup_data[dataset_meta.gt_name], subgroup_data[dataset_meta.score_name], c=\"black\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.xlim(-0.1, 1.1)\n",
    "    plt.ylim(-0.1, 1.1)\n",
    "    print(f\"{STAGE_OUTPUT_PATH}/{os.path.basename(PARAM_DATA_IN_PATH)}_ROC_{pattern}.pdf\")\n",
    "    plt.savefig(f\"{STAGE_OUTPUT_PATH}/{os.path.basename(PARAM_DATA_IN_PATH)}_ROC_{pattern}.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(subgroup_data[dataset_meta.gt_name], subgroup_data[dataset_meta.score_name], drop_intermediate=True)\n",
    "    plt.plot(recall, precision, c=\"black\")\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.xlim(-0.1, 1.1)\n",
    "    plt.ylim(-0.1, 1.1)\n",
    "    plt.savefig(f\"{STAGE_OUTPUT_PATH}/{os.path.basename(PARAM_DATA_IN_PATH)}_PR_{pattern}.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subroc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
