{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Plots of Metrics Values on search Data vs. holdout-generalizability Data with Empirical Distribution Plots of each Depicted Subgroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Values for Papermill Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "PARAM_FULL_RESULT_SET_PATH = \"../outputs/p_value_augmented_result_set.csv\"\n",
    "PARAM_FILTERED_RESULT_SET_PATH = \"../outputs/p_value_filtered_result_set.csv\"\n",
    "PARAM_SEARCH_QF_PATH = \"../outputs/interestingness_measure.pickle\"\n",
    "PARAM_AUGMENTATION_QF_PATH = \"../outputs/p_value_augmentation_interestingness_measure.pickle\"\n",
    "PARAM_PLOT_BASENAME = \"generalizability_plot\"\n",
    "PARAM_DATA_IN_PATH = \"../../data\"\n",
    "PARAM_MODELS_IN_PATH = \"../../models\"\n",
    "\n",
    "PARAM_DATASET_NAME = \"OpenML Adult\"\n",
    "PARAM_DATASET_STAGE = None\n",
    "PARAM_MODEL_NAME = \"sklearn_gaussian_nb_adult_4_splits\"\n",
    "\n",
    "PARAM_PLOT_XMIN = 0\n",
    "PARAM_PLOT_XMAX = 1\n",
    "PARAM_PLOT_YMIN = 0\n",
    "PARAM_PLOT_YMAX = 1\n",
    "PARAM_PLOT_XLABEL = \"PRC AUC on Search Data\"\n",
    "PARAM_PLOT_YLABEL = \"PRC AUC on Test Data\"\n",
    "PARAM_PLOTS_SPLIT = \"False\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subroc.datasets.metadata import to_DatasetName\n",
    "from subroc.datasets.reader import DatasetReader, DatasetStage, meta_dict\n",
    "from subroc.model_serialization import deserialize\n",
    "from subroc.quality_functions.base_qf import PredictionType, OptimizationMode\n",
    "from subroc.quality_functions.soft_classifier_target import SoftClassifierTarget\n",
    "from subroc.quality_functions.metric_qf_wrapper import MetricType\n",
    "from subroc import util\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pysubgroup as ps\n",
    "\n",
    "# fill environment variables into params\n",
    "PARAM_FULL_RESULT_SET_PATH = util.prepend_experiment_output_path(PARAM_FULL_RESULT_SET_PATH)\n",
    "PARAM_FILTERED_RESULT_SET_PATH = util.prepend_experiment_output_path(PARAM_FILTERED_RESULT_SET_PATH)\n",
    "PARAM_SEARCH_QF_PATH = util.prepend_experiment_output_path(PARAM_SEARCH_QF_PATH)\n",
    "PARAM_AUGMENTATION_QF_PATH = util.prepend_experiment_output_path(PARAM_AUGMENTATION_QF_PATH)\n",
    "PARAM_DATA_IN_PATH = util.prepend_experiment_output_path(PARAM_DATA_IN_PATH)\n",
    "PARAM_MODELS_IN_PATH = util.prepend_experiment_output_path(PARAM_MODELS_IN_PATH)\n",
    "\n",
    "# convert param strings to bools\n",
    "PARAM_PLOTS_SPLIT = util.str_to_bool(PARAM_PLOTS_SPLIT)\n",
    "\n",
    "# get environment variables\n",
    "STAGE_OUTPUT_PATH = os.environ.get(\"STAGE_OUTPUT_PATH\", \"../outputs\")\n",
    "\n",
    "# Dataset\n",
    "dataset_reader = DatasetReader(PARAM_DATA_IN_PATH)\n",
    "\n",
    "DATA_OUT_PATH = f\"{STAGE_OUTPUT_PATH}/data/processed\"\n",
    "if not os.path.exists(DATA_OUT_PATH):\n",
    "    os.makedirs(DATA_OUT_PATH)\n",
    "\n",
    "DATASET_NAME = to_DatasetName(PARAM_DATASET_NAME)\n",
    "\n",
    "if DATASET_NAME is None:\n",
    "    print(f\"dataset name '{PARAM_DATASET_NAME}' not supported.\")\n",
    "\n",
    "if PARAM_DATASET_STAGE is None:\n",
    "    DATASET_STAGE = DatasetStage.PROCESSED_MODEL_READY\n",
    "else:\n",
    "    DATASET_STAGE = DatasetStage(PARAM_DATASET_STAGE)\n",
    "\n",
    "# Model\n",
    "model = deserialize(PARAM_MODELS_IN_PATH, PARAM_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data and preprocess it for the model\n",
    "dataset_meta = meta_dict[DATASET_NAME]\n",
    "\n",
    "# prepare classification predictions\n",
    "dataset_meta.prediction_type = PredictionType.CLASSIFICATION_SOFT\n",
    "\n",
    "search_data = None\n",
    "p_value_augmentation_data = None\n",
    "holdout_generalizability_data = None\n",
    "if DATASET_STAGE == DatasetStage.PROCESSED_MODEL_READY:\n",
    "    search_data = dataset_reader._read_processed(dataset_meta, \"model_ready_test.csv\", \",\")\n",
    "    p_value_augmentation_data = dataset_reader._read_processed(dataset_meta, \"model_ready_holdout_significance.csv\", \",\")\n",
    "    holdout_generalizability_data = dataset_reader._read_processed(dataset_meta, \"model_ready_holdout_generalizability.csv\", \",\")\n",
    "\n",
    "    search_data_x = search_data.loc[:, search_data.columns != dataset_meta.gt_name]\n",
    "    search_data[dataset_meta.score_name] = model.predict(search_data_x)\n",
    "    p_value_augmentation_data_x = p_value_augmentation_data.loc[:, p_value_augmentation_data.columns != dataset_meta.gt_name]\n",
    "    p_value_augmentation_data[dataset_meta.score_name] = model.predict(p_value_augmentation_data_x)\n",
    "    holdout_generalizability_data_x = holdout_generalizability_data.loc[:, holdout_generalizability_data.columns != dataset_meta.gt_name]\n",
    "    holdout_generalizability_data[dataset_meta.score_name] = model.predict(holdout_generalizability_data_x)\n",
    "\n",
    "    # save data with predictions\n",
    "    out_path = DATA_OUT_PATH + \"/\" + dataset_meta.dataset_dir\n",
    "    if not os.path.exists(out_path):\n",
    "        os.mkdir(out_path)\n",
    "\n",
    "    search_data.to_csv(out_path + \"/\" + \"model_predicted_test.csv\", index=False)\n",
    "    holdout_generalizability_data.to_csv(out_path + \"/\" + \"model_predicted_holdout_generalizability.csv\", index=False)\n",
    "elif DATASET_STAGE == DatasetStage.PROCESSED_MODEL_PREDICTED:\n",
    "    search_data = dataset_reader._read_processed(dataset_meta, \"model_predicted_test.csv\", \",\")\n",
    "    p_value_augmentation_data = dataset_reader._read_processed(dataset_meta, \"model_predicted_holdout_significance.csv\", \",\")\n",
    "    holdout_generalizability_data = dataset_reader._read_processed(dataset_meta, \"model_predicted_holdout_generalizability.csv\", \",\")\n",
    "elif DATASET_STAGE == DatasetStage.PROCESSED_PERMUTED_MODEL_PREDICTED:\n",
    "    search_data = dataset_reader._read_processed(dataset_meta, \"permuted_model_predicted_test.csv\", \",\")\n",
    "    p_value_augmentation_data = dataset_reader._read_processed(dataset_meta, \"permuted_model_predicted_holdout_significance.csv\", \",\")\n",
    "    holdout_generalizability_data = dataset_reader._read_processed(dataset_meta, \"permuted_model_predicted_holdout_generalizability.csv\", \",\")\n",
    "\n",
    "# sd objects\n",
    "target = SoftClassifierTarget(dataset_meta.gt_name, dataset_meta.score_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Full Result Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_result_set = pd.read_csv(f\"{PARAM_FULL_RESULT_SET_PATH}\")\n",
    "full_result_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Filtered Result Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_result_set = pd.read_csv(f\"{PARAM_FILTERED_RESULT_SET_PATH}\")\n",
    "filtered_result_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Configure the Interestingness Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_configure_qf(data, qf_path):\n",
    "    with open(qf_path, \"rb\") as qf_file:\n",
    "        qf = pickle.load(qf_file)\n",
    "\n",
    "    if isinstance(qf, ps.GeneralizationAwareQF):\n",
    "        qf = qf.qf\n",
    "\n",
    "    qf.calculate_constant_statistics(data, target)\n",
    "\n",
    "    # Disable any significance-related changes to the qf value\n",
    "    qf.subgroup_size_weight = 0\n",
    "    qf.subgroup_class_balance_weight = 0\n",
    "    qf.random_sampling_p_value_factor = False\n",
    "    qf.random_sampling_normalization = False\n",
    "\n",
    "    # update the representation of the qf-specific constraints if necessary\n",
    "    if hasattr(qf, \"constraints\"):\n",
    "        for constraint in qf.constraints:\n",
    "            if hasattr(constraint, \"update\"):\n",
    "                constraint.update(data)\n",
    "    \n",
    "    return qf\n",
    "\n",
    "\n",
    "search_qf = read_and_configure_qf(search_data, PARAM_SEARCH_QF_PATH)\n",
    "p_value_augmentation_qf = read_and_configure_qf(p_value_augmentation_data, PARAM_AUGMENTATION_QF_PATH)\n",
    "holdout_generalizability_qf = read_and_configure_qf(holdout_generalizability_data, PARAM_SEARCH_QF_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Plot Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metric_value(pattern, qf, data):\n",
    "    # sort data and set up some datastructures to access sorted data\n",
    "    dataset_sorted_by_score = data.sort_values(dataset_meta.score_name)\n",
    "    scores_sorted = dataset_sorted_by_score.loc[:, dataset_meta.score_name]\n",
    "    gt_sorted_by_score = dataset_sorted_by_score.loc[:, dataset_meta.gt_name]\n",
    "    sorted_to_original_index = [index for index, _ in dataset_sorted_by_score.iterrows()]\n",
    "\n",
    "    # recreate the pysubgroup object for the subgroup with a representation for the dataset\n",
    "    sel_conjunction = util.from_str_Conjunction(pattern)\n",
    "    subgroup = util.create_subgroup(data, sel_conjunction.selectors)\n",
    "\n",
    "    # calculate statistics\n",
    "    statistics = qf.calculate_statistics(subgroup, target, data)\n",
    "\n",
    "    # check constraints\n",
    "    if not ps.constraints_satisfied(\n",
    "            qf.constraints,\n",
    "            subgroup,\n",
    "            statistics,\n",
    "            data,\n",
    "    ):\n",
    "        return np.nan\n",
    "    \n",
    "    # get true and predicted labels for subgroup cover\n",
    "    sorted_subgroup_representation = \\\n",
    "        [subgroup.representation[original_index] for original_index in sorted_to_original_index]\n",
    "    sorted_subgroup_y_true = gt_sorted_by_score[sorted_subgroup_representation].to_numpy()\n",
    "    sorted_subgroup_y_pred = scores_sorted[sorted_subgroup_representation].to_numpy()\n",
    "    \n",
    "    # compute the metric values\n",
    "    return qf.metric(sorted_subgroup_y_true, sorted_subgroup_y_pred)\n",
    "\n",
    "\n",
    "full_search_metric_values = []\n",
    "full_holdout_generalizability_metric_values = []\n",
    "\n",
    "for i, result in enumerate(full_result_set.itertuples()):\n",
    "    full_search_metric_values.append(calculate_metric_value(result.pattern, search_qf, search_data))\n",
    "    full_holdout_generalizability_metric_values.append(calculate_metric_value(result.pattern, holdout_generalizability_qf, holdout_generalizability_data))\n",
    "\n",
    "filtered_search_metric_values = []\n",
    "filtered_holdout_generalizability_metric_values = []\n",
    "\n",
    "for i, result in enumerate(filtered_result_set.itertuples()):\n",
    "    filtered_search_metric_values.append(calculate_metric_value(result.pattern, search_qf, search_data))\n",
    "    filtered_holdout_generalizability_metric_values.append(calculate_metric_value(result.pattern, holdout_generalizability_qf, holdout_generalizability_data))\n",
    "\n",
    "search_overall_metric_value = calculate_metric_value(\"Dataset\", search_qf, search_data)\n",
    "holdout_generalizability_overall_metric_value = calculate_metric_value(\"Dataset\", holdout_generalizability_qf, holdout_generalizability_data)\n",
    "\n",
    "print(\"full_search_metric_values:\", full_search_metric_values)\n",
    "print(\"full_holdout_generalizability_metric_values:\", full_holdout_generalizability_metric_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def scatter_plot(search_metric_values, holdout_generalizability_metric_values, ax, c, linewidths, filtered):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    only_xs = []\n",
    "\n",
    "    for search_metric_value, holdout_generalizability_metric_value in zip(search_metric_values, holdout_generalizability_metric_values):\n",
    "        if np.isnan(holdout_generalizability_metric_value):\n",
    "            only_xs.append(search_metric_value)\n",
    "            continue\n",
    "            \n",
    "        xs.append(search_metric_value)\n",
    "        ys.append(holdout_generalizability_metric_value)\n",
    "\n",
    "    ax.scatter(search_metric_values, holdout_generalizability_metric_values, s=30, c=c, marker=\"x\", linewidths=linewidths)\n",
    "\n",
    "    for x in only_xs:\n",
    "        if filtered:\n",
    "            ax.axvline(x, color=\"black\", linestyle=\"--\", linewidth=0.5)\n",
    "        else:\n",
    "            ax.axvline(x, color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "\n",
    "def distribution_histogram(ax, pattern, data, qf, title):\n",
    "    sg_metric = calculate_metric_value(pattern, qf, data)\n",
    "\n",
    "    # get sampling distribution\n",
    "\n",
    "    ## recreate the pysubgroup object for the subgroup with a representation for the dataset\n",
    "    sel_conjunction = util.from_str_Conjunction(pattern)\n",
    "    subgroup = util.create_subgroup(data, sel_conjunction.selectors)\n",
    "\n",
    "    subgroup_size = sum(subgroup.representation)\n",
    "    subgroup_labels = data.loc[subgroup.representation, target.gt_name]\n",
    "    negatives_count = subgroup_size - np.sum(subgroup_labels)\n",
    "\n",
    "    invocatoin_key = f\"{subgroup_size}:{negatives_count}\"\n",
    "    if invocatoin_key in qf.random_sampling_distributions:\n",
    "        distribution = qf.random_sampling_distributions[invocatoin_key]\n",
    "    else:\n",
    "        distribution = []\n",
    "    \n",
    "    # compute exceptionality\n",
    "    exceptionality = sg_metric\n",
    "\n",
    "    if qf.relative_quality:\n",
    "        exceptionality = exceptionality - qf.dataset_quality\n",
    "\n",
    "    if qf.metric_type == MetricType.Score:\n",
    "        exceptionality = -exceptionality\n",
    "\n",
    "    if qf.optimization_mode == OptimizationMode.Minimal:\n",
    "        exceptionality = -exceptionality\n",
    "    elif qf.optimization_mode == OptimizationMode.Exceptional:\n",
    "        exceptionality = abs(exceptionality)\n",
    "\n",
    "    ax.hist(distribution, bins=\"auto\")\n",
    "\n",
    "    ax.axvline(exceptionality, color=\"red\", linewidth=1)\n",
    "\n",
    "    ax.set_xlabel(\"Exceptionality (Metric Difference)\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "\n",
    "    ax.set_title(f\"{title} |sg|={subgroup_size}, |N(sg)|={negatives_count}\")\n",
    "\n",
    "\n",
    "figs = []\n",
    "patterns = [result.pattern for result in full_result_set.itertuples()]\n",
    "\n",
    "for pattern, point in zip(patterns, zip(full_search_metric_values, full_holdout_generalizability_metric_values)):\n",
    "    if PARAM_PLOTS_SPLIT:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(5, 4))\n",
    "    else:\n",
    "        fig, (ax, ax1, ax2) = plt.subplots(1, 3, figsize=(15,4))\n",
    "\n",
    "    scatter_plot(full_search_metric_values, full_holdout_generalizability_metric_values, ax, c=\"gray\", linewidths=0.5, filtered=False)\n",
    "    scatter_plot(filtered_search_metric_values, filtered_holdout_generalizability_metric_values, ax, c=\"black\", linewidths=1, filtered=True)\n",
    "\n",
    "    if not np.isnan(point[1]):\n",
    "        scatter_plot([point[0]], [point[1]], ax, c=\"red\", linewidths=1, filtered=False)\n",
    "    else:\n",
    "        ax.axvline(point[0], color=\"red\", linewidth=0.1)\n",
    "    \n",
    "    ax.grid(True, which=\"major\", linestyle=\"dotted\")\n",
    "\n",
    "    if PARAM_PLOT_XMIN is not None:\n",
    "        ax.set_xlim(left=PARAM_PLOT_XMIN)\n",
    "    if PARAM_PLOT_XMAX is not None:\n",
    "        ax.set_xlim(right=PARAM_PLOT_XMAX)\n",
    "    if PARAM_PLOT_YMIN is not None:\n",
    "        ax.set_ylim(bottom=PARAM_PLOT_YMIN)\n",
    "    if PARAM_PLOT_YMAX is not None:\n",
    "        ax.set_ylim(top=PARAM_PLOT_YMAX)\n",
    "\n",
    "    ax.set_xlabel(PARAM_PLOT_XLABEL)\n",
    "    ax.set_ylabel(PARAM_PLOT_YLABEL)\n",
    "\n",
    "    ax.axvline(search_overall_metric_value, color=\"black\", linewidth=0.75)\n",
    "    ax.axhline(holdout_generalizability_overall_metric_value, color=\"black\", linewidth=0.75)\n",
    "\n",
    "    passed_filtering = False\n",
    "    for filtered_result in filtered_result_set.itertuples():\n",
    "        if filtered_result.pattern == pattern:\n",
    "            passed_filtering = True\n",
    "            break\n",
    "    filtering_str = \"filtering passed\" if passed_filtering else \"filtering not passed\"\n",
    "\n",
    "    ax.set_title(f\"{pattern}\\n{filtering_str}\")\n",
    "\n",
    "    if PARAM_PLOTS_SPLIT:\n",
    "        figs.append(fig)\n",
    "        fig, ax1 = plt.subplots(1, 1, figsize=(5, 4))\n",
    "\n",
    "    distribution_histogram(ax1, pattern, search_data, search_qf, \"Search Distribution\")\n",
    "\n",
    "    if PARAM_PLOTS_SPLIT:\n",
    "        figs.append(fig)\n",
    "        fig, ax2 = plt.subplots(1, 1, figsize=(5, 4))\n",
    "\n",
    "    distribution_histogram(ax2, pattern, p_value_augmentation_data, p_value_augmentation_qf, \"Filtering Distribution\")\n",
    "\n",
    "    figs.append(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.backends.backend_pdf as backend_pdf\n",
    "\n",
    "pdf = backend_pdf.PdfPages(f\"{STAGE_OUTPUT_PATH}/{PARAM_PLOT_BASENAME}.pdf\")\n",
    "\n",
    "for fig in figs:\n",
    "    pdf.savefig(fig)\n",
    "\n",
    "pdf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subroc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
