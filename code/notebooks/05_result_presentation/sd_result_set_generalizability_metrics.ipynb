{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Metrics about Generalizability of Metrics Values on search Data vs. holdout-generalizability Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Values for Papermill Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "PARAM_FULL_RESULT_SET_PATH = \"../outputs/p_value_augmented_result_set.csv\"\n",
    "PARAM_FILTERED_RESULT_SET_PATH = \"../outputs/p_value_filtered_result_set.csv\"\n",
    "PARAM_QF_PATH = \"../outputs/interestingness_measure.pickle\"\n",
    "PARAM_METRICS_BASENAME = \"generalizability_metrics\"\n",
    "PARAM_DATA_IN_PATH = \"../../data\"\n",
    "PARAM_MODELS_IN_PATH = \"../../models\"\n",
    "\n",
    "PARAM_DATASET_NAME = \"OpenML Adult\"\n",
    "PARAM_DATASET_STAGE = None\n",
    "PARAM_MODEL_NAME = \"model\"\n",
    "\n",
    "PARAM_PLOT_XMIN = 0\n",
    "PARAM_PLOT_XMAX = 1\n",
    "PARAM_PLOT_YMIN = 0\n",
    "PARAM_PLOT_YMAX = 1\n",
    "PARAM_PLOT_XLABEL = \"PRC AUC on Search Data\"\n",
    "PARAM_PLOT_YLABEL = \"PRC AUC on Test Data\"\n",
    "\n",
    "PARAM_TOP_K_COLUMN = \"interestingness\"\n",
    "PARAM_TOP_K = 5\n",
    "\n",
    "PARAM_ENABLED_METRICS = [\"number of full subgroups\", \"number of filtered subgroups\", \"number of subgroups with unmet constraints in full subgroups\",\n",
    "                         \"number of subgroups with unmet constraints in filtered subgroups\", \"full spearman correlation\", \"full spearman p-value\",\n",
    "                         \"filtered spearman correlation\", \"filtered spearman p-value\", \"full MSE with subtractive exceptionality\", \"full MAE with subtractive exceptionality\",\n",
    "                         \"filtered MSE with subtractive exceptionality\", \"filtered MAE with subtractive exceptionality\", \"full MSE with fractional exceptionality\",\n",
    "                         \"full MAE with fractional exceptionality\", \"filtered MSE with fractional exceptionality\", \"filtered MAE with fractional exceptionality\",\n",
    "                         \"full mean subtractive search exceptionality\", \"full mean subtractive test exceptionality\", \"filtered mean subtractive search exceptionality\",\n",
    "                         \"filtered mean subtractive test exceptionality\", \"full mean fractional search exceptionality\", \"full mean fractional test exceptionality\",\n",
    "                         \"filtered mean fractional search exceptionality\", \"filtered mean fractional test exceptionality\"]\n",
    "                        # others: \"full mean pairwise IoU\", \"top-k full mean pairwise IoU\", \"filtered mean pairwise IoU\", \"top-k filtered mean pairwise IoU\", \"empirical false discovery rate\", \"empirical power\",\n",
    "                        # \"number of top-k full subgroups\", \"number of top-k filtered subgroups\", \"top-k full mean subtractive search exceptionality\", \"top-k filtered mean subtractive search exceptionality\"\n",
    "                        # \"top-k full mean fractional search exceptionality\", \"top-k filtered mean fractional search exceptionality\"\n",
    "                        # \"full mean search cover size\", \"full min search cover size\", \"full max search cover size\"\n",
    "                        # \"top-k full mean search cover size\", \"top-k full min search cover size\", \"top-k full max search cover size\"\n",
    "                        # \"filtered mean search cover size\", \"filtered min search cover size\", \"filtered max search cover size\"\n",
    "                        # \"top-k filtered mean search cover size\", \"top-k filtered min search cover size\", \"top-k filtered max search cover size\"\n",
    "                        # \"full mean search NCR\", \"full min search NCR\", \"full max search NCR\"\n",
    "                        # \"top-k full mean search NCR\", \"top-k full min search NCR\", \"top-k full max search NCR\"\n",
    "                        # \"filtered mean search NCR\", \"filtered min search NCR\", \"filtered max search NCR\"\n",
    "                        # \"top-k filtered mean search NCR\", \"top-k filtered min search NCR\", \"top-k filtered max search NCR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subroc.datasets.metadata import to_DatasetName\n",
    "from subroc.datasets.reader import DatasetReader, DatasetStage, meta_dict\n",
    "from subroc.model_serialization import deserialize\n",
    "from subroc.quality_functions.base_qf import PredictionType, OptimizationMode\n",
    "from subroc.quality_functions.soft_classifier_target import SoftClassifierTarget\n",
    "from subroc.quality_functions.metric_qf_wrapper import MetricType\n",
    "from subroc import util\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pickle\n",
    "import pysubgroup as ps\n",
    "\n",
    "# fill environment variables into params\n",
    "PARAM_FULL_RESULT_SET_PATH = util.prepend_experiment_output_path(PARAM_FULL_RESULT_SET_PATH)\n",
    "PARAM_FILTERED_RESULT_SET_PATH = util.prepend_experiment_output_path(PARAM_FILTERED_RESULT_SET_PATH)\n",
    "PARAM_QF_PATH = util.prepend_experiment_output_path(PARAM_QF_PATH)\n",
    "PARAM_DATA_IN_PATH = util.prepend_experiment_output_path(PARAM_DATA_IN_PATH)\n",
    "PARAM_MODELS_IN_PATH = util.prepend_experiment_output_path(PARAM_MODELS_IN_PATH)\n",
    "\n",
    "# get environment variables\n",
    "STAGE_OUTPUT_PATH = os.environ.get(\"STAGE_OUTPUT_PATH\", \"../outputs\")\n",
    "\n",
    "# Dataset\n",
    "dataset_reader = DatasetReader(PARAM_DATA_IN_PATH)\n",
    "\n",
    "DATA_OUT_PATH = f\"{STAGE_OUTPUT_PATH}/data/processed\"\n",
    "if not os.path.exists(DATA_OUT_PATH):\n",
    "    os.makedirs(DATA_OUT_PATH)\n",
    "\n",
    "DATASET_NAME = to_DatasetName(PARAM_DATASET_NAME)\n",
    "\n",
    "if DATASET_NAME is None:\n",
    "    print(f\"dataset name '{PARAM_DATASET_NAME}' not supported.\")\n",
    "\n",
    "if PARAM_DATASET_STAGE is None:\n",
    "    DATASET_STAGE = DatasetStage.PROCESSED_MODEL_READY\n",
    "else:\n",
    "    DATASET_STAGE = DatasetStage(PARAM_DATASET_STAGE)\n",
    "\n",
    "# Model\n",
    "model = deserialize(PARAM_MODELS_IN_PATH, PARAM_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data and preprocess it for the model\n",
    "dataset_meta = meta_dict[DATASET_NAME]\n",
    "\n",
    "# prepare classification predictions\n",
    "dataset_meta.prediction_type = PredictionType.CLASSIFICATION_SOFT\n",
    "\n",
    "search_data = None\n",
    "holdout_generalizability_data = None\n",
    "if DATASET_STAGE == DatasetStage.PROCESSED_MODEL_READY:\n",
    "    search_data = dataset_reader._read_processed(dataset_meta, \"model_ready_test.csv\", \",\")\n",
    "    holdout_generalizability_data = dataset_reader._read_processed(dataset_meta, \"model_ready_holdout_generalizability.csv\", \",\")\n",
    "\n",
    "    search_data_x = search_data.loc[:, search_data.columns != dataset_meta.gt_name]\n",
    "    search_data[dataset_meta.score_name] = model.predict(search_data_x)\n",
    "    holdout_generalizability_data_x = holdout_generalizability_data.loc[:, holdout_generalizability_data.columns != dataset_meta.gt_name]\n",
    "    holdout_generalizability_data[dataset_meta.score_name] = model.predict(holdout_generalizability_data_x)\n",
    "\n",
    "    # save data with predictions\n",
    "    out_path = DATA_OUT_PATH + \"/\" + dataset_meta.dataset_dir\n",
    "    if not os.path.exists(out_path):\n",
    "        os.mkdir(out_path)\n",
    "\n",
    "    search_data.to_csv(out_path + \"/\" + \"model_predicted_test.csv\", index=False)\n",
    "    holdout_generalizability_data.to_csv(out_path + \"/\" + \"model_predicted_holdout_generalizability.csv\", index=False)\n",
    "elif DATASET_STAGE == DatasetStage.PROCESSED_MODEL_PREDICTED:\n",
    "    search_data = dataset_reader._read_processed(dataset_meta, \"model_predicted_test.csv\", \",\")\n",
    "    holdout_generalizability_data = dataset_reader._read_processed(dataset_meta, \"model_predicted_holdout_generalizability.csv\", \",\")\n",
    "elif DATASET_STAGE == DatasetStage.PROCESSED_PERMUTED_MODEL_PREDICTED:\n",
    "    search_data = dataset_reader._read_processed(dataset_meta, \"permuted_model_predicted_test.csv\", \",\")\n",
    "    holdout_generalizability_data = dataset_reader._read_processed(dataset_meta, \"permuted_model_predicted_holdout_generalizability.csv\", \",\")\n",
    "\n",
    "# sd objects\n",
    "target = SoftClassifierTarget(dataset_meta.gt_name, dataset_meta.score_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Full Result Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_result_set = pd.read_csv(f\"{PARAM_FULL_RESULT_SET_PATH}\")\n",
    "full_result_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Filtered Result Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_result_set = pd.read_csv(f\"{PARAM_FILTERED_RESULT_SET_PATH}\")\n",
    "filtered_result_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Top-k Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_full_result_set = full_result_set.copy().sort_values(by=PARAM_TOP_K_COLUMN, ascending=False)[:PARAM_TOP_K]\n",
    "top_k_filtered_result_set = filtered_result_set.copy().sort_values(by=PARAM_TOP_K_COLUMN, ascending=False)[:PARAM_TOP_K]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Configure the Interestingness Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_configure_qf(data):\n",
    "    with open(PARAM_QF_PATH, \"rb\") as qf_file:\n",
    "        qf = pickle.load(qf_file)\n",
    "\n",
    "    if isinstance(qf, ps.GeneralizationAwareQF):\n",
    "        qf = qf.qf\n",
    "\n",
    "    # Disable any significance-related changes to the qf value\n",
    "    qf.subgroup_size_weight = 0\n",
    "    qf.subgroup_class_balance_weight = 0\n",
    "    qf.random_sampling_p_value_factor = False\n",
    "    qf.random_sampling_normalization = False\n",
    "\n",
    "    # update the representation of the qf-specific constraints if necessary\n",
    "    if hasattr(qf, \"constraints\"):\n",
    "        for constraint in qf.constraints:\n",
    "            if hasattr(constraint, \"update\"):\n",
    "                constraint.update(data)\n",
    "    \n",
    "    return qf\n",
    "\n",
    "\n",
    "search_qf = read_and_configure_qf(search_data)\n",
    "holdout_generalizability_qf = read_and_configure_qf(holdout_generalizability_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Plot Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metric_value(pattern, qf, data):\n",
    "    # sort data and set up some datastructures to access sorted data\n",
    "    dataset_sorted_by_score = data.sort_values(dataset_meta.score_name)\n",
    "    scores_sorted = dataset_sorted_by_score.loc[:, dataset_meta.score_name]\n",
    "    gt_sorted_by_score = dataset_sorted_by_score.loc[:, dataset_meta.gt_name]\n",
    "    sorted_to_original_index = [index for index, _ in dataset_sorted_by_score.iterrows()]\n",
    "\n",
    "    # recreate the pysubgroup object for the subgroup with a representation for the dataset\n",
    "    sel_conjunction = util.from_str_Conjunction(pattern)\n",
    "    subgroup = util.create_subgroup(data, sel_conjunction.selectors)\n",
    "\n",
    "    # calculate statistics\n",
    "    statistics = qf.calculate_statistics(subgroup, target, data)\n",
    "\n",
    "    # check constraints\n",
    "    if not ps.constraints_satisfied(\n",
    "            qf.constraints,\n",
    "            subgroup,\n",
    "            statistics,\n",
    "            data,\n",
    "    ):\n",
    "        return np.nan\n",
    "    \n",
    "    # get true and predicted labels for subgroup cover\n",
    "    sorted_subgroup_representation = \\\n",
    "        [subgroup.representation[original_index] for original_index in sorted_to_original_index]\n",
    "    sorted_subgroup_y_true = gt_sorted_by_score[sorted_subgroup_representation].to_numpy()\n",
    "    sorted_subgroup_y_pred = scores_sorted[sorted_subgroup_representation].to_numpy()\n",
    "    \n",
    "    # compute the metric values\n",
    "    return qf.metric(sorted_subgroup_y_true, sorted_subgroup_y_pred)\n",
    "\n",
    "\n",
    "full_search_metric_values = []\n",
    "full_holdout_generalizability_metric_values = []\n",
    "\n",
    "for i, result in enumerate(full_result_set.itertuples()):\n",
    "    full_search_metric_values.append(calculate_metric_value(result.pattern, search_qf, search_data))\n",
    "    full_holdout_generalizability_metric_values.append(calculate_metric_value(result.pattern, holdout_generalizability_qf, holdout_generalizability_data))\n",
    "\n",
    "top_k_full_search_metric_values = []\n",
    "\n",
    "for i, result in enumerate(top_k_full_result_set.itertuples()):\n",
    "    top_k_full_search_metric_values.append(calculate_metric_value(result.pattern, search_qf, search_data))\n",
    "\n",
    "top_k_full_search_metric_values = np.array(top_k_full_search_metric_values)\n",
    "\n",
    "filtered_search_metric_values = []\n",
    "filtered_holdout_generalizability_metric_values = []\n",
    "\n",
    "for i, result in enumerate(filtered_result_set.itertuples()):\n",
    "    filtered_search_metric_values.append(calculate_metric_value(result.pattern, search_qf, search_data))\n",
    "    filtered_holdout_generalizability_metric_values.append(calculate_metric_value(result.pattern, holdout_generalizability_qf, holdout_generalizability_data))\n",
    "\n",
    "top_k_filtered_search_metric_values = []\n",
    "\n",
    "for i, result in enumerate(top_k_filtered_result_set.itertuples()):\n",
    "    top_k_filtered_search_metric_values.append(calculate_metric_value(result.pattern, search_qf, search_data))\n",
    "\n",
    "top_k_filtered_search_metric_values = np.array(top_k_filtered_search_metric_values)\n",
    "\n",
    "search_overall_metric_value = calculate_metric_value(\"Dataset\", search_qf, search_data)\n",
    "holdout_generalizability_overall_metric_value = calculate_metric_value(\"Dataset\", holdout_generalizability_qf, holdout_generalizability_data)\n",
    "\n",
    "print(\"full_search_metric_values:\", full_search_metric_values)\n",
    "print(\"full_holdout_generalizability_metric_values:\", full_holdout_generalizability_metric_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Subgroups (with Unmet Constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {}\n",
    "\n",
    "metrics_dict[\"number of full subgroups\"] = len(full_result_set)\n",
    "metrics_dict[\"number of top-k full subgroups\"] = len(top_k_full_result_set)\n",
    "metrics_dict[\"number of filtered subgroups\"] = len(filtered_result_set)\n",
    "metrics_dict[\"number of top-k filtered subgroups\"] = len(top_k_filtered_result_set)\n",
    "\n",
    "metrics_dict[\"number of subgroups with unmet constraints in full subgroups\"] = len([np.nan for metric_value in full_holdout_generalizability_metric_values if np.isnan(metric_value)])\n",
    "metrics_dict[\"number of subgroups with unmet constraints in filtered subgroups\"] = len([np.nan for metric_value in filtered_holdout_generalizability_metric_values if np.isnan(metric_value)])\n",
    "\n",
    "# remove nan values\n",
    "if np.count_nonzero(~np.isnan(np.array(full_holdout_generalizability_metric_values).astype(float))) > 0:  # there must be non-nans\n",
    "    full_points = np.array([[search_metric_value, holdout_generalizability_metric_value] for search_metric_value, holdout_generalizability_metric_value in zip(full_search_metric_values, full_holdout_generalizability_metric_values) if not np.isnan(holdout_generalizability_metric_value)])\n",
    "    full_search_metric_values = full_points[:, 0]\n",
    "    full_holdout_generalizability_metric_values = full_points[:, 1]\n",
    "else:\n",
    "    full_points = np.array([])\n",
    "    full_search_metric_values = np.array([])\n",
    "    full_holdout_generalizability_metric_values = np.array([])\n",
    "\n",
    "if np.count_nonzero(~np.isnan(np.array(filtered_holdout_generalizability_metric_values).astype(float))) > 0:  # there must be non-nans\n",
    "    filtered_points = np.array([[search_metric_value, holdout_generalizability_metric_value] for search_metric_value, holdout_generalizability_metric_value in zip(filtered_search_metric_values, filtered_holdout_generalizability_metric_values) if not np.isnan(holdout_generalizability_metric_value)])\n",
    "    filtered_search_metric_values = filtered_points[:, 0]\n",
    "    filtered_holdout_generalizability_metric_values = filtered_points[:, 1]\n",
    "else:\n",
    "    filtered_points = np.array([])\n",
    "    filtered_search_metric_values = np.array([])\n",
    "    filtered_holdout_generalizability_metric_values = np.array([])\n",
    "\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Spearman Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_spearman_result = spearmanr(full_search_metric_values, full_holdout_generalizability_metric_values)\n",
    "metrics_dict[\"full spearman correlation\"] = full_spearman_result.statistic\n",
    "metrics_dict[\"full spearman p-value\"] = full_spearman_result.pvalue\n",
    "\n",
    "filtered_spearman_result = spearmanr(filtered_search_metric_values, filtered_holdout_generalizability_metric_values)\n",
    "metrics_dict[\"filtered spearman correlation\"] = filtered_spearman_result.statistic\n",
    "metrics_dict[\"filtered spearman p-value\"] = filtered_spearman_result.pvalue\n",
    "\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtractive_exceptionality(qf, metric_values, overall_metric_value):\n",
    "    relative_metric_values = metric_values - overall_metric_value\n",
    "\n",
    "    if qf.metric_type == MetricType.Score:\n",
    "        relative_metric_values = -relative_metric_values\n",
    "\n",
    "    if qf.optimization_mode == OptimizationMode.Minimal:\n",
    "        relative_metric_values = -relative_metric_values\n",
    "    \n",
    "    return relative_metric_values\n",
    "\n",
    "\n",
    "def fractional_exceptionality(qf, metric_values, overall_metric_value):\n",
    "    relative_metric_values = metric_values / overall_metric_value\n",
    "\n",
    "    if (qf.metric_type == MetricType.Score) != (qf.optimization_mode == OptimizationMode.Minimal):\n",
    "        if 0 in relative_metric_values:\n",
    "            return []\n",
    "        \n",
    "        relative_metric_values = 1 / relative_metric_values\n",
    "    \n",
    "    return relative_metric_values\n",
    "\n",
    "\n",
    "filtered_search_subtractive_exceptionality = subtractive_exceptionality(search_qf, filtered_search_metric_values, search_overall_metric_value)\n",
    "filtered_search_fractional_exceptionality = fractional_exceptionality(search_qf, filtered_search_metric_values, search_overall_metric_value)\n",
    "\n",
    "top_k_filtered_search_subtractive_exceptionality = subtractive_exceptionality(search_qf, top_k_filtered_search_metric_values, search_overall_metric_value)\n",
    "top_k_filtered_search_fractional_exceptionality = fractional_exceptionality(search_qf, top_k_filtered_search_metric_values, search_overall_metric_value)\n",
    "\n",
    "full_search_subtractive_exceptionality = subtractive_exceptionality(search_qf, full_search_metric_values, search_overall_metric_value)\n",
    "full_search_fractional_exceptionality = fractional_exceptionality(search_qf, full_search_metric_values, search_overall_metric_value)\n",
    "\n",
    "top_k_full_search_subtractive_exceptionality = subtractive_exceptionality(search_qf, top_k_full_search_metric_values, search_overall_metric_value)\n",
    "top_k_full_search_fractional_exceptionality = fractional_exceptionality(search_qf, top_k_full_search_metric_values, search_overall_metric_value)\n",
    "\n",
    "filtered_holdout_generalizability_subtractive_exceptionality = subtractive_exceptionality(holdout_generalizability_qf, filtered_holdout_generalizability_metric_values, holdout_generalizability_overall_metric_value)\n",
    "filtered_holdout_generalizability_fractional_exceptionality = fractional_exceptionality(holdout_generalizability_qf, filtered_holdout_generalizability_metric_values, holdout_generalizability_overall_metric_value)\n",
    "\n",
    "full_holdout_generalizability_subtractive_exceptionality = subtractive_exceptionality(holdout_generalizability_qf, full_holdout_generalizability_metric_values, holdout_generalizability_overall_metric_value)\n",
    "full_holdout_generalizability_fractional_exceptionality = fractional_exceptionality(holdout_generalizability_qf, full_holdout_generalizability_metric_values, holdout_generalizability_overall_metric_value)\n",
    "\n",
    "metrics_dict[\"full MSE with subtractive exceptionality\"] = np.nan if len(full_search_subtractive_exceptionality) == 0 or len(full_holdout_generalizability_subtractive_exceptionality) == 0 else mean_squared_error(full_search_subtractive_exceptionality, full_holdout_generalizability_subtractive_exceptionality)\n",
    "metrics_dict[\"full MAE with subtractive exceptionality\"] = np.nan if len(full_search_subtractive_exceptionality) == 0 or len(full_holdout_generalizability_subtractive_exceptionality) == 0 else mean_absolute_error(full_search_subtractive_exceptionality, full_holdout_generalizability_subtractive_exceptionality)\n",
    "\n",
    "metrics_dict[\"filtered MSE with subtractive exceptionality\"] = np.nan if len(filtered_search_subtractive_exceptionality) == 0 or len(filtered_holdout_generalizability_subtractive_exceptionality) == 0 else mean_squared_error(filtered_search_subtractive_exceptionality, filtered_holdout_generalizability_subtractive_exceptionality)\n",
    "metrics_dict[\"filtered MAE with subtractive exceptionality\"] = np.nan if len(filtered_search_subtractive_exceptionality) == 0 or len(filtered_holdout_generalizability_subtractive_exceptionality) == 0 else mean_absolute_error(filtered_search_subtractive_exceptionality, filtered_holdout_generalizability_subtractive_exceptionality)\n",
    "\n",
    "metrics_dict[\"full MSE with fractional exceptionality\"] = np.nan if len(full_search_fractional_exceptionality) == 0 or len(full_holdout_generalizability_fractional_exceptionality) == 0 else mean_squared_error(full_search_fractional_exceptionality, full_holdout_generalizability_fractional_exceptionality)\n",
    "metrics_dict[\"full MAE with fractional exceptionality\"] = np.nan if len(full_search_fractional_exceptionality) == 0 or len(full_holdout_generalizability_fractional_exceptionality) == 0 else mean_absolute_error(full_search_fractional_exceptionality, full_holdout_generalizability_fractional_exceptionality)\n",
    "\n",
    "metrics_dict[\"filtered MSE with fractional exceptionality\"] = np.nan if len(filtered_search_fractional_exceptionality) == 0 or len(filtered_holdout_generalizability_fractional_exceptionality) == 0 else mean_squared_error(filtered_search_fractional_exceptionality, filtered_holdout_generalizability_fractional_exceptionality)\n",
    "metrics_dict[\"filtered MAE with fractional exceptionality\"] = np.nan if len(filtered_search_fractional_exceptionality) == 0 or len(filtered_holdout_generalizability_fractional_exceptionality) == 0 else mean_absolute_error(filtered_search_fractional_exceptionality, filtered_holdout_generalizability_fractional_exceptionality)\n",
    "\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Location Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict[\"full mean subtractive search exceptionality\"] = np.mean(full_search_subtractive_exceptionality)\n",
    "metrics_dict[\"full mean subtractive test exceptionality\"] = np.mean(full_holdout_generalizability_subtractive_exceptionality)\n",
    "\n",
    "metrics_dict[\"top-k full mean subtractive search exceptionality\"] = np.mean(top_k_full_search_subtractive_exceptionality)\n",
    "\n",
    "metrics_dict[\"filtered mean subtractive search exceptionality\"] = np.mean(filtered_search_subtractive_exceptionality)\n",
    "metrics_dict[\"filtered mean subtractive test exceptionality\"] = np.mean(filtered_holdout_generalizability_subtractive_exceptionality)\n",
    "\n",
    "metrics_dict[\"top-k filtered mean subtractive search exceptionality\"] = np.mean(top_k_filtered_search_subtractive_exceptionality)\n",
    "\n",
    "metrics_dict[\"full mean fractional search exceptionality\"] = np.mean(full_search_fractional_exceptionality)\n",
    "metrics_dict[\"full mean fractional test exceptionality\"] = np.mean(full_holdout_generalizability_fractional_exceptionality)\n",
    "\n",
    "metrics_dict[\"top-k full mean fractional search exceptionality\"] = np.mean(top_k_full_search_fractional_exceptionality)\n",
    "\n",
    "metrics_dict[\"filtered mean fractional search exceptionality\"] = np.mean(filtered_search_fractional_exceptionality)\n",
    "metrics_dict[\"filtered mean fractional test exceptionality\"] = np.mean(filtered_holdout_generalizability_fractional_exceptionality)\n",
    "\n",
    "metrics_dict[\"top-k filtered mean fractional search exceptionality\"] = np.mean(top_k_filtered_search_fractional_exceptionality)\n",
    "\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Mean Pairwise IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_result_set_no_empty_pattern = full_result_set[full_result_set[\"pattern\"] != \"Dataset\"]\n",
    "top_k_full_result_set_no_empty_pattern = top_k_full_result_set[top_k_full_result_set[\"pattern\"] != \"Dataset\"]\n",
    "filtered_result_set_no_empty_pattern = filtered_result_set[filtered_result_set[\"pattern\"] != \"Dataset\"]\n",
    "top_k_filtered_result_set_no_empty_pattern = top_k_filtered_result_set[top_k_filtered_result_set[\"pattern\"] != \"Dataset\"]\n",
    "\n",
    "metrics_dict[\"full mean pairwise IoU\"] = util.mean_pairwise_iou(full_result_set_no_empty_pattern, search_data)\n",
    "metrics_dict[\"top-k full mean pairwise IoU\"] = util.mean_pairwise_iou(top_k_full_result_set_no_empty_pattern, search_data)\n",
    "metrics_dict[\"filtered mean pairwise IoU\"] = util.mean_pairwise_iou(filtered_result_set_no_empty_pattern, search_data)\n",
    "metrics_dict[\"top-k filtered mean pairwise IoU\"] = util.mean_pairwise_iou(top_k_filtered_result_set_no_empty_pattern, search_data)\n",
    "\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Empirical FDR (False Discovery Rate) / Power of the Statistical Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_false_discoveries = np.sum(filtered_holdout_generalizability_subtractive_exceptionality <= 0)\n",
    "num_discoveries = len(filtered_points)\n",
    "num_true_discoveries = num_discoveries - num_false_discoveries\n",
    "num_potential_true_discoveries = np.sum(full_holdout_generalizability_subtractive_exceptionality > 0)\n",
    "\n",
    "metrics_dict[\"empirical false discovery rate\"] = num_false_discoveries / num_discoveries if num_discoveries > 0 else np.nan\n",
    "metrics_dict[\"empirical power\"] = num_true_discoveries / num_potential_true_discoveries if num_potential_true_discoveries > 0 else np.nan\n",
    "\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Cover Size Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"full mean search cover size\", \"full min search cover size\", \"full max search cover size\"\n",
    "# \"top-k full mean search cover size\", \"top-k full min search cover size\", \"top-k full max search cover size\"\n",
    "# \"filtered mean search cover size\", \"filtered min search cover size\", \"filtered max search cover size\"\n",
    "# \"top-k filtered mean search cover size\", \"top-k filtered min search cover size\", \"top-k filtered max search cover size\"\n",
    "\n",
    "\n",
    "def calculate_cover_size(pattern, data):\n",
    "    # recreate the pysubgroup object for the subgroup with a representation for the dataset\n",
    "    sel_conjunction = util.from_str_Conjunction(pattern)\n",
    "    subgroup = util.create_subgroup(data, sel_conjunction.selectors)\n",
    "\n",
    "    return sum(subgroup.representation)\n",
    "\n",
    "\n",
    "full_cover_sizes = full_result_set_no_empty_pattern[\"pattern\"].map(lambda x: calculate_cover_size(x, search_data))\n",
    "\n",
    "metrics_dict[\"full mean search cover size\"] = full_cover_sizes.mean()\n",
    "metrics_dict[\"full min search cover size\"] = full_cover_sizes.min()\n",
    "metrics_dict[\"full max search cover size\"] = full_cover_sizes.max()\n",
    "\n",
    "top_k_full_cover_sizes = top_k_full_result_set_no_empty_pattern[\"pattern\"].map(lambda x: calculate_cover_size(x, search_data))\n",
    "\n",
    "metrics_dict[\"top-k full mean search cover size\"] = top_k_full_cover_sizes.mean()\n",
    "metrics_dict[\"top-k full min search cover size\"] = top_k_full_cover_sizes.min()\n",
    "metrics_dict[\"top-k full max search cover size\"] = top_k_full_cover_sizes.max()\n",
    "\n",
    "filtered_cover_sizes = filtered_result_set_no_empty_pattern[\"pattern\"].map(lambda x: calculate_cover_size(x, search_data))\n",
    "\n",
    "metrics_dict[\"filtered mean search cover size\"] = filtered_cover_sizes.mean()\n",
    "metrics_dict[\"filtered min search cover size\"] = filtered_cover_sizes.min()\n",
    "metrics_dict[\"filtered max search cover size\"] = filtered_cover_sizes.max()\n",
    "\n",
    "top_k_filtered_cover_sizes = top_k_filtered_result_set_no_empty_pattern[\"pattern\"].map(lambda x: calculate_cover_size(x, search_data))\n",
    "\n",
    "metrics_dict[\"top-k filtered mean search cover size\"] = top_k_filtered_cover_sizes.mean()\n",
    "metrics_dict[\"top-k filtered min search cover size\"] = top_k_filtered_cover_sizes.min()\n",
    "metrics_dict[\"top-k filtered max search cover size\"] = top_k_filtered_cover_sizes.max()\n",
    "\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the NCR Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"full mean search NCR\", \"full min search NCR\", \"full max search NCR\"\n",
    "# \"top-k full mean search NCR\", \"top-k full min search NCR\", \"top-k full max search NCR\"\n",
    "# \"filtered mean search NCR\", \"filtered min search NCR\", \"filtered max search NCR\"\n",
    "# \"top-k filtered mean search NCR\", \"top-k filtered min search NCR\", \"top-k filtered max search NCR\"\n",
    "\n",
    "\n",
    "def calculate_negatives(pattern, data, data_meta):\n",
    "    # recreate the pysubgroup object for the subgroup with a representation for the dataset\n",
    "    sel_conjunction = util.from_str_Conjunction(pattern)\n",
    "    subgroup = util.create_subgroup(data, sel_conjunction.selectors)\n",
    "\n",
    "    if data_meta.gt_true_value in data[data_meta.gt_name]:\n",
    "        negatives_mask = data[data_meta.gt_name] != data_meta.gt_true_value\n",
    "    else:\n",
    "        negatives_mask = data[data_meta.gt_name] == 0\n",
    "\n",
    "    return sum(subgroup.representation[negatives_mask])\n",
    "\n",
    "\n",
    "def calculate_ncr(pattern, data, data_meta):\n",
    "    cover_size = calculate_cover_size(pattern, data)\n",
    "\n",
    "    if cover_size == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    negatives = calculate_negatives(pattern, data, data_meta)\n",
    "\n",
    "    return negatives / cover_size\n",
    "\n",
    "\n",
    "full_ncrs = full_result_set_no_empty_pattern[\"pattern\"].map(lambda x: calculate_ncr(x, search_data, dataset_meta))\n",
    "\n",
    "metrics_dict[\"full mean search NCR\"] = full_ncrs.mean()\n",
    "metrics_dict[\"full min search NCR\"] = full_ncrs.min()\n",
    "metrics_dict[\"full max search NCR\"] = full_ncrs.max()\n",
    "\n",
    "top_k_full_ncrs = top_k_full_result_set_no_empty_pattern[\"pattern\"].map(lambda x: calculate_ncr(x, search_data, dataset_meta))\n",
    "\n",
    "metrics_dict[\"top-k full mean search NCR\"] = top_k_full_ncrs.mean()\n",
    "metrics_dict[\"top-k full min search NCR\"] = top_k_full_ncrs.min()\n",
    "metrics_dict[\"top-k full max search NCR\"] = top_k_full_ncrs.max()\n",
    "\n",
    "filtered_ncrs = filtered_result_set_no_empty_pattern[\"pattern\"].map(lambda x: calculate_ncr(x, search_data, dataset_meta))\n",
    "\n",
    "metrics_dict[\"filtered mean search NCR\"] = filtered_ncrs.mean()\n",
    "metrics_dict[\"filtered min search NCR\"] = filtered_ncrs.min()\n",
    "metrics_dict[\"filtered max search NCR\"] = filtered_ncrs.max()\n",
    "\n",
    "top_k_filtered_ncrs = top_k_filtered_result_set_no_empty_pattern[\"pattern\"].map(lambda x: calculate_ncr(x, search_data, dataset_meta))\n",
    "\n",
    "metrics_dict[\"top-k filtered mean search NCR\"] = top_k_filtered_ncrs.mean()\n",
    "metrics_dict[\"top-k filtered min search NCR\"] = top_k_filtered_ncrs.min()\n",
    "metrics_dict[\"top-k filtered max search NCR\"] = top_k_filtered_ncrs.max()\n",
    "\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Metrics by PARAM_ENABLED_METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PARAM_ENABLED_METRICS is not None:\n",
    "    metrics_dict = {enabled_metric: metrics_dict[enabled_metric] for enabled_metric in PARAM_ENABLED_METRICS}\n",
    "\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(metrics_dict, index=[0])\n",
    "metrics_df.to_csv(f\"{STAGE_OUTPUT_PATH}/{PARAM_METRICS_BASENAME}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subroc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
