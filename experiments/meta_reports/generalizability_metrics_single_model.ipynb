{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine into One DataFrame the Generalizability Metrics from Experiments on All Datasets for One Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Papermill Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "PARAM_DEFINITIONS_PATH = \"../definitions\"\n",
    "PARAM_OUTPUT_PATH = \"../outputs\"\n",
    "\n",
    "###### Switch these parameters ######\n",
    "# parameters for base setup\n",
    "PARAM_COVER_SIZE_WEIGHT = 0\n",
    "PARAM_CLASS_BALANCE_WEIGHT = 0\n",
    "PARAM_ENABLED_GENERALIZATION_AWARENESS = False\n",
    "PARAM_ENABLED_SIGNIFICANCE_FILTERING = False\n",
    "\n",
    "# parameters for setup of our full method\n",
    "# PARAM_COVER_SIZE_WEIGHT = 1\n",
    "# PARAM_CLASS_BALANCE_WEIGHT = 1\n",
    "# PARAM_ENABLED_GENERALIZATION_AWARENESS = True\n",
    "# PARAM_ENABLED_SIGNIFICANCE_FILTERING = True\n",
    "\n",
    "PARAM_INPUT_EXPERIMENTS = {\n",
    "    \"sklearn_naive_bayes_GaussianNB\": [\"exp-18\", \"exp-19\"] + [f\"exp-{i}\" for i in range(38, 43+1)],\n",
    "    \"xgboost_XGBClassifier\": [f\"exp-{i}\" for i in range(44, 51+1)],\n",
    "    \"sklearn_linear_model_LogisticRegression\": [f\"exp-{i}\" for i in range(52, 59+1)],\n",
    "    \"sklearn_ensemble_RandomForestClassifier\": [f\"exp-{i}\" for i in range(85, 92+1)],\n",
    "    \"sklearn_neural_network_MLPClassifier\": [f\"exp-{i}\" for i in range(93, 100+1)]}\n",
    "PARAM_INPUT_STAGES = {\"exp-18\": \"stage-14\", \"exp-19\": \"stage-14\"} | {f\"exp-{i}\": f\"stage-{14}\" for i in range(38, 59+1)} | {f\"exp-{i}\": f\"stage-{14}\" for i in range(85, 100+1)}\n",
    "PARAM_INPUT_FILES = {f\"exp-{i}\": [[f\"generalizability_metrics_{PARAM_COVER_SIZE_WEIGHT}_{PARAM_CLASS_BALANCE_WEIGHT}_False_average_ranking_loss_{PARAM_ENABLED_GENERALIZATION_AWARENESS}.csv\", \"ARL\"],\n",
    "                                [f\"generalizability_metrics_{PARAM_COVER_SIZE_WEIGHT}_{PARAM_CLASS_BALANCE_WEIGHT}_False_prc_auc_score_{PARAM_ENABLED_GENERALIZATION_AWARENESS}.csv\", \"PR AUC\"],\n",
    "                                [f\"generalizability_metrics_{PARAM_COVER_SIZE_WEIGHT}_{PARAM_CLASS_BALANCE_WEIGHT}_False_sklearn.metrics.roc_auc_score_{PARAM_ENABLED_GENERALIZATION_AWARENESS}.csv\", \"ROC AUC\"]] for i in [18, 19]} \\\n",
    "    | {f\"exp-{i}\": [[f\"generalizability_metrics_{PARAM_COVER_SIZE_WEIGHT}_{PARAM_CLASS_BALANCE_WEIGHT}_average_ranking_loss_{PARAM_ENABLED_GENERALIZATION_AWARENESS}.csv\", \"ARL\"],\n",
    "                    [f\"generalizability_metrics_{PARAM_COVER_SIZE_WEIGHT}_{PARAM_CLASS_BALANCE_WEIGHT}_prc_auc_score_{PARAM_ENABLED_GENERALIZATION_AWARENESS}.csv\", \"PR AUC\"],\n",
    "                    [f\"generalizability_metrics_{PARAM_COVER_SIZE_WEIGHT}_{PARAM_CLASS_BALANCE_WEIGHT}_sklearn.metrics.roc_auc_score_{PARAM_ENABLED_GENERALIZATION_AWARENESS}.csv\", \"ROC AUC\"]] for i in list(range(38, 59+1)) + list(range(85, 100+1))}\n",
    "\n",
    "PARAM_MODEL = \"xgboost_XGBClassifier\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Input Experiment for Requested Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_experiments = PARAM_INPUT_EXPERIMENTS[PARAM_MODEL]\n",
    "\n",
    "print(PARAM_INPUT_EXPERIMENTS)\n",
    "print(PARAM_INPUT_STAGES)\n",
    "print(PARAM_INPUT_FILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Combine Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "metrics = set()\n",
    "stage_dicts = []\n",
    "\n",
    "for exp in input_experiments:\n",
    "    with open(f\"{PARAM_DEFINITIONS_PATH}/{exp}/stage-00/global_params.yaml\") as global_params_file:\n",
    "        global_params = yaml.load(global_params_file, Loader=yaml.FullLoader)\n",
    "\n",
    "    exp_base_row = {\"experiment\": exp, \"dataset\": global_params[\"PARAM_DATASET_NAME\"], \"model_type\": global_params[\"PARAM_MODEL_TYPE\"]}\n",
    "\n",
    "    stage = PARAM_INPUT_STAGES[exp]\n",
    "    for input_filename, performance_measure_name in PARAM_INPUT_FILES[exp]:\n",
    "        try:\n",
    "            stage_row_part = {key: value[0] for key, value in pd.read_csv(f\"{PARAM_OUTPUT_PATH}/{exp}/{stage}/{input_filename}\").to_dict().items()}\n",
    "            metrics.update(stage_row_part.keys())\n",
    "\n",
    "            print(f\"{PARAM_OUTPUT_PATH}/{exp}/{stage}/{input_filename} values: {stage_row_part}\")\n",
    "        except FileNotFoundError:\n",
    "            stage_row_part = {}\n",
    "\n",
    "            print(f\"{PARAM_OUTPUT_PATH}/{exp}/{stage}/{input_filename} not found\")\n",
    "\n",
    "        stage_row_part |= {\"performance_measure\": performance_measure_name}\n",
    "        stage_row = exp_base_row | stage_row_part\n",
    "        stage_dicts.append(stage_row)\n",
    "\n",
    "all_outputs_df = pd.DataFrame(stage_dicts)\n",
    "\n",
    "meta_reports_path = f\"{PARAM_OUTPUT_PATH}/meta_reports/generalizability_metrics\"\n",
    "os.makedirs(meta_reports_path, exist_ok=True)\n",
    "\n",
    "all_outputs_df.to_csv(f\"{meta_reports_path}/generalizability_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn into LaTeX Table Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def combine_num_subgroups(row, col1, col2, col3=None):\n",
    "    val1 = format(row[col1], \"{0:.0f}\")\n",
    "    val2 = format(row[col2], \"{0:.0f}\")\n",
    "\n",
    "    if col3 is not None:\n",
    "        val3 = format(row[col3], \"{0:.0f}\")\n",
    "        return f\"{val1}/{val2}/{val3}\"\n",
    "    else:\n",
    "        return f\"{val1}/{val2}\"\n",
    "\n",
    "\n",
    "def format(x, fstring):\n",
    "    if isinstance(x, str):\n",
    "        return x\n",
    "\n",
    "    if np.isnan(x):\n",
    "        return \"-\"\n",
    "\n",
    "    return fstring.format(x)\n",
    "\n",
    "\n",
    "def makecell(str):\n",
    "    return r\"\\makecell{\" + str + r\"}\"\n",
    "\n",
    "\n",
    "def rotatebox(str):\n",
    "    return r\"\\rotatebox{90}{\" + str + r\"}\"\n",
    "\n",
    "\n",
    "num_subgroups_column_name = None\n",
    "mean_exceptionality_column_name = None\n",
    "mean_pairwise_iou_column_name = None\n",
    "cover_size_column_name = None\n",
    "ncr_column_name = None\n",
    "\n",
    "if PARAM_ENABLED_SIGNIFICANCE_FILTERING:\n",
    "    mean_exceptionality_column_name = \"top-k filtered mean subtractive search exceptionality\"\n",
    "    mean_pairwise_iou_column_name = \"top-k filtered mean pairwise IoU\"\n",
    "    cover_size_column_name = \"top-k filtered mean search cover size\"\n",
    "    ncr_column_name = \"top-k filtered mean search NCR\"\n",
    "    intermediate_num_subgroups_column_name = \"number of filtered subgroups\"\n",
    "    final_num_subgroups_column_name = \"number of top-k filtered subgroups\"\n",
    "\n",
    "    num_subgroups_column_name = \"combined number of subgroups\"\n",
    "    all_outputs_df[num_subgroups_column_name] = all_outputs_df.loc[:, [final_num_subgroups_column_name, intermediate_num_subgroups_column_name, \"number of full subgroups\"]] \\\n",
    "                                                .apply(lambda x: combine_num_subgroups(x, final_num_subgroups_column_name, intermediate_num_subgroups_column_name, \"number of full subgroups\"), axis=1)\n",
    "    num_subgroups_column_header_name = r\"Result Set Size\\\\(Top-5/\\\\Significant/\\\\Original)\"\n",
    "else:\n",
    "    mean_exceptionality_column_name = \"top-k full mean subtractive search exceptionality\"\n",
    "    mean_pairwise_iou_column_name = \"top-k full mean pairwise IoU\"\n",
    "    cover_size_column_name = \"top-k full mean search cover size\"\n",
    "    ncr_column_name = \"top-k full mean search NCR\"\n",
    "    top_k_num_subgroups_column_name = \"number of top-k full subgroups\"\n",
    "    filtered_top_k_num_subgroups_column_name = \"number of filtered top-k subgroups\"\n",
    "\n",
    "    num_subgroups_column_name = \"combined number of subgroups\"\n",
    "    all_outputs_df[filtered_top_k_num_subgroups_column_name] = [\"(not implemented, count manually)\"]*len(all_outputs_df)\n",
    "    all_outputs_df[num_subgroups_column_name] = all_outputs_df.loc[:, [filtered_top_k_num_subgroups_column_name, top_k_num_subgroups_column_name]] \\\n",
    "                                                .apply(lambda x: combine_num_subgroups(x, filtered_top_k_num_subgroups_column_name, top_k_num_subgroups_column_name), axis=1)\n",
    "    num_subgroups_column_header_name = r\"Result Set Size\\\\(Significant/\\\\Top-5)\"\n",
    "\n",
    "latex_df = all_outputs_df.loc[:, [\"dataset\", \"performance_measure\", mean_exceptionality_column_name, mean_pairwise_iou_column_name, cover_size_column_name, ncr_column_name, num_subgroups_column_name]]\n",
    "\n",
    "latex_df[mean_exceptionality_column_name] = latex_df[mean_exceptionality_column_name].map(lambda x: format(x, \"{0:.2f}\"))\n",
    "latex_df[mean_pairwise_iou_column_name] = latex_df[mean_pairwise_iou_column_name].map(lambda x: format(x, \"{0:.2f}\"))\n",
    "latex_df[cover_size_column_name] = latex_df[cover_size_column_name].map(lambda x: format(x, \"{0:.0f}\"))\n",
    "latex_df[ncr_column_name] = latex_df[ncr_column_name].map(lambda x: format(x, \"{0:.2f}\"))\n",
    "latex_df[num_subgroups_column_name] = latex_df[num_subgroups_column_name].map(lambda x: format(x, \"{0:.0f}\"))\n",
    "\n",
    "latex_df.rename(columns={\n",
    "    \"dataset\": \"Dataset\", \n",
    "    \"performance_measure\": makecell(r\"Interestingness\\\\Measure\"),\n",
    "    mean_exceptionality_column_name: rotatebox(makecell(r\"Mean\\\\Exceptionality\")),\n",
    "    mean_pairwise_iou_column_name: rotatebox(makecell(r\"Mean\\\\Pairwise IoU\")),\n",
    "    cover_size_column_name: rotatebox(makecell(r\"Mean\\\\Cover Size\")),\n",
    "    ncr_column_name: rotatebox(makecell(r\"Mean NCR\")),\n",
    "    num_subgroups_column_name: rotatebox(makecell(num_subgroups_column_header_name)),\n",
    "    }, inplace=True)\n",
    "\n",
    "datasets_line_breaks_dict = {\n",
    "   \"UCI Credit Approval\": r\"UCI Credit Approval\",\n",
    "   \"UCI Breast Cancer Wisconsin\": r\"UCI Breast\\\\Cancer Wisconsin\",\n",
    "   \"Statlog (German Credit Data)\": r\"Statlog (German\\\\Credit Data)\",\n",
    "   \"UCI Mushroom\": r\"UCI Mushroom\",\n",
    "   \"UCI Credit Card Clients\": r\"UCI Credit\\\\Card Clients\",\n",
    "   \"UCI Bank Marketing\": r\"UCI Bank\\\\Marketing\",\n",
    "   \"OpenML Adult\": r\"OpenML Adult\",\n",
    "   \"UCI Census-Income (KDD)\": r\"UCI Census-Income\\\\(KDD)\",\n",
    "}\n",
    "\n",
    "multiindex_columns = [\"Dataset\", r\"\\makecell{Interestingness\\\\Measure}\"] \n",
    "multiindex = pd.MultiIndex.from_frame(latex_df[multiindex_columns])\n",
    "latex_df.drop(multiindex_columns, axis=1, inplace=True)\n",
    "latex_df.set_index(multiindex, inplace=True)\n",
    "\n",
    "latex_df.sort_index(inplace=True)\n",
    "latex_df.sort_index(level=0, ascending=False, inplace=True, key=lambda x: [list(datasets_line_breaks_dict.keys()).index(idx) for idx in x])\n",
    "\n",
    "datasets = latex_df.index.levels[0]\n",
    "\n",
    "latex_df.style.to_latex(f\"{meta_reports_path}/generalizability_metrics_{PARAM_MODEL}_{PARAM_COVER_SIZE_WEIGHT}_{PARAM_CLASS_BALANCE_WEIGHT}_{PARAM_ENABLED_GENERALIZATION_AWARENESS}_{PARAM_ENABLED_SIGNIFICANCE_FILTERING}.tex\",\n",
    "                        column_format=\"llrrrrl\",\n",
    "                        hrules=True,\n",
    "                        clines=\"skip-last;data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subroc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
