{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine into One DataFrame the Runtime Measurements from Experiments of All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_with_weighting = [f\"exp-{i}\" for i in range(118, 126)]\n",
    "experiments_no_weighting = [f\"exp-{i}\" for i in range(126, 134)]\n",
    "experiments_0_1_weighting = [f\"exp-{i}\" for i in range(134, 142)]\n",
    "experiments_0_3_weighting = [f\"exp-{i}\" for i in range(142, 150)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Papermill Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "PARAM_DEFINITIONS_PATH = \"../definitions\"\n",
    "PARAM_OUTPUT_PATH = \"../outputs\"\n",
    "\n",
    "PARAM_WEIGHTINGS_EXPERIMENTS = {\n",
    "    \"1\": experiments_with_weighting,\n",
    "    \"0.3\": experiments_0_3_weighting,\n",
    "    \"0.1\": experiments_0_1_weighting,\n",
    "    \"0\": experiments_no_weighting,\n",
    "}\n",
    "\n",
    "PARAM_INPUT_STAGE = \"stage-06\"\n",
    "PARAM_INPUT_FILENAME = \"statistics_merged_runtimes.csv\"\n",
    "PARAM_DEPTH = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Combine Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "meta_reports_path = f\"{PARAM_OUTPUT_PATH}/meta_reports\"\n",
    "if not os.path.exists(meta_reports_path):\n",
    "    os.mkdir(meta_reports_path)\n",
    "\n",
    "out_dir = f\"{meta_reports_path}/optimistic_estimates\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Combine Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oe_to_string(oe):\n",
    "    return r\"\\multicolumn{1}{c}{On}\" if oe else r\"\\multicolumn{1}{c}{Off}\"\n",
    "\n",
    "\n",
    "def get_results(weighting_experiments):\n",
    "    stage_dicts = []\n",
    "\n",
    "    for weighting, experiments in weighting_experiments.items():\n",
    "        for exp in experiments:\n",
    "            with open(f\"{PARAM_DEFINITIONS_PATH}/{exp}/stage-00/global_params.yaml\") as global_params_file:\n",
    "                global_params = yaml.load(global_params_file, Loader=yaml.FullLoader)\n",
    "\n",
    "            exp_base_row = {\n",
    "                \"weighting\": weighting,\n",
    "                \"dataset\": global_params[\"PARAM_DATASET_NAME\"],\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                stage_df = pd.read_csv(f\"{PARAM_OUTPUT_PATH}/{exp}/{PARAM_INPUT_STAGE}/{PARAM_INPUT_FILENAME}\")\n",
    "\n",
    "                for _, row in stage_df[stage_df[\"depth\"] == PARAM_DEPTH].iterrows():\n",
    "                    row_part = {\"qf_name\": row[\"qf_name\"], \"optimistic_estimate\": oe_to_string(row[\"optimistic_estimate\"]), \"time_median\": row[\"time_median\"], \"time_std\": row[\"time_std\"]}\n",
    "                    stage_dicts.append(exp_base_row | row_part)\n",
    "            except FileNotFoundError:\n",
    "                null_row_part = {\"qf_name\": None, \"num_visited_subgroups_speedup\": None, \"time_speedup\": None}\n",
    "                stage_dicts.append(exp_base_row | null_row_part)\n",
    "                print(f\"{PARAM_OUTPUT_PATH}/{exp}/{PARAM_INPUT_STAGE}/{PARAM_INPUT_FILENAME} not found\")\n",
    "\n",
    "    all_outputs_df = pd.DataFrame(stage_dicts)\n",
    "\n",
    "    return all_outputs_df\n",
    "\n",
    "\n",
    "all_outputs_df = get_results(PARAM_WEIGHTINGS_EXPERIMENTS)\n",
    "all_outputs_df.to_csv(f\"{out_dir}/optimistic_estimate_runtimes_combined.csv\", index=False)\n",
    "all_outputs_df.set_index([\"dataset\", \"qf_name\", \"weighting\", \"optimistic_estimate\"], inplace=True)\n",
    "all_outputs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn into LaTeX Table Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "performance_measure_name_replacements = {\n",
    "        \"average_ranking_loss\": \"ARL\",\n",
    "        \"roc_auc_score\": \"ROC AUC\",\n",
    "        \"prc_auc_score\": \"PR AUC\"\n",
    "    }\n",
    "\n",
    "\n",
    "def str_format_time_median_speedup(this_median, this_std):\n",
    "    this_str = f\"{this_median:.1f}\"\n",
    "    return this_str\n",
    "\n",
    "\n",
    "latex_time_median_dicts = {dataset: {} for dataset in all_outputs_df.index.levels[0]}\n",
    "\n",
    "std_over_median_list = []\n",
    "for dataset, qf_name, weighting, optimistic_estimate in itertools.product(*all_outputs_df.index.levels):\n",
    "    if (dataset, qf_name, weighting, optimistic_estimate) not in all_outputs_df.index:\n",
    "        continue\n",
    "\n",
    "    time_median_with_weighting = all_outputs_df.loc[(dataset, qf_name, weighting, optimistic_estimate), \"time_median\"]\n",
    "    time_std_with_weighting = all_outputs_df.loc[(dataset, qf_name, weighting, optimistic_estimate), \"time_std\"]\n",
    "\n",
    "    latex_time_median_dicts[dataset][f\"{performance_measure_name_replacements[qf_name]}*{weighting}*{optimistic_estimate}\"] = str_format_time_median_speedup(time_median_with_weighting, time_std_with_weighting)\n",
    "\n",
    "    std_over_median_list.append(time_std_with_weighting/time_median_with_weighting)\n",
    "    std_threshold = 0.1\n",
    "    if std_over_median_list[-1] > std_threshold:\n",
    "        print(dataset, f\"has std/median > {std_threshold}\")\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 8})\n",
    "plt.gcf().set_size_inches(3, 3)\n",
    "plt.hist(std_over_median_list, bins=50)\n",
    "plt.xlabel(\"(Standard Deviation)/Median\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.subplots_adjust(left=0.2, bottom=0.15)\n",
    "plt.savefig(f\"{out_dir}/optimistic_estimates_time_median_std_histogram.pdf\")\n",
    "\n",
    "datasets_line_breaks_dict = {\n",
    "   \"UCI Credit Approval\": r\"UCI Credit Approval\",\n",
    "   \"UCI Breast Cancer Wisconsin\": r\"UCI Breast\\\\Cancer Wisconsin\",\n",
    "   \"Statlog (German Credit Data)\": r\"Statlog (German\\\\Credit Data)\",\n",
    "   \"UCI Mushroom\": r\"UCI Mushroom\",\n",
    "   \"UCI Credit Card Clients\": r\"UCI Credit\\\\Card Clients\",\n",
    "   \"UCI Bank Marketing\": r\"UCI Bank\\\\Marketing\",\n",
    "   \"OpenML Adult\": r\"OpenML Adult\",\n",
    "   \"UCI Census-Income (KDD)\": r\"UCI Census-Income\\\\(KDD)\",\n",
    "}\n",
    "\n",
    "latex_dataset_column_name = r\"\\cmidrule(lr){2-3}\\cmidrule(lr){4-5}\\cmidrule(lr){6-7}\\cmidrule(lr){8-9}Dataset\"\n",
    "latex_time_median_dicts = [{latex_dataset_column_name: dataset} | rest_dict for dataset, rest_dict in latex_time_median_dicts.items()]\n",
    "latex_time_median_df = pd.DataFrame(latex_time_median_dicts)\n",
    "latex_time_median_df.set_index(latex_dataset_column_name, inplace=True)\n",
    "latex_time_median_df.sort_index(ascending=False, inplace=True, key=lambda x: [list(datasets_line_breaks_dict.keys()).index(idx) for idx in x])\n",
    "\n",
    "columns_multiindex_lists = []\n",
    "for column in latex_time_median_df.columns.values:\n",
    "    if len(column.split(\"*\")) > 1:\n",
    "        columns_multiindex_lists.append(column.split(\"*\"))\n",
    "\n",
    "print(columns_multiindex_lists)\n",
    "columns_multiindex = pd.MultiIndex.from_arrays(np.array(columns_multiindex_lists).T)\n",
    "latex_time_median_df.columns = columns_multiindex\n",
    "\n",
    "for qf_name in all_outputs_df.index.levels[1]:\n",
    "    qf_latex_time_median_df = latex_time_median_df[performance_measure_name_replacements[qf_name]].copy()\n",
    "\n",
    "    columns = qf_latex_time_median_df.columns.values\n",
    "    qf_latex_time_median_df[(\"\", latex_dataset_column_name)] = qf_latex_time_median_df.index\n",
    "    qf_latex_time_median_df = qf_latex_time_median_df[[(\"\", latex_dataset_column_name), *columns]]\n",
    "\n",
    "    qf_latex_time_median_df.to_latex(f\"{out_dir}/optimistic_estimates_time_median_table_{qf_name}.tex\", index=False, column_format=r\"lrrrrrrrr\", multicolumn_format=\"c\")\n",
    "    print(qf_latex_time_median_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subroc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
